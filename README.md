# ğŸš— PredicciÃ³n del Precio de VehÃ­culos Usados con Modelos de Machine Learning

## ğŸ“Œ DescripciÃ³n del Proyecto

Este proyecto tiene como finalidad desarrollar, comparar y optimizar modelos de regresiÃ³n para predecir el precio de vehÃ­culos usados en el mercado del Reino Unido. A travÃ©s del uso de tÃ©cnicas de machine learning como **Random Forest** y **XGBoost**, se buscÃ³ minimizar el **Error Absoluto Medio (MAE)** como mÃ©trica de evaluaciÃ³n principal.

El proceso abarcÃ³ desde la limpieza y preprocesamiento de datos hasta la implementaciÃ³n de estrategias avanzadas de optimizaciÃ³n, incluyendo bÃºsqueda de hiperparÃ¡metros y selecciÃ³n de caracterÃ­sticas.

---

## ğŸ§  Modelos Utilizados

- RegresiÃ³n Lineal *(descartada por bajo rendimiento)*
- Random Forest Regressor
- XGBoost Regressor

---

## âš™ï¸ MetodologÃ­a

### ğŸ” Preprocesamiento de Datos

- ImputaciÃ³n de valores nulos por media agrupada (`make`)
- EliminaciÃ³n de duplicados y outliers (`year = 2060`)
- CodificaciÃ³n categÃ³rica con **One-Hot Encoding**
- NormalizaciÃ³n con **Min-Max Scaling**
- DivisiÃ³n del dataset: **70% entrenamiento / 30% prueba**

---

### ğŸ“Š EvaluaciÃ³n Inicial

| Modelo            | MAE (Baseline) |
|-------------------|----------------|
| RegresiÃ³n Lineal  | 2962.55        |
| Random Forest     | 1440.67        |
| XGBoost           | 1496.08        |

---

## ğŸ› ï¸ OptimizaciÃ³n de Modelos

Se utilizaron tres estrategias principales para mejorar el rendimiento:

- Ajuste manual de hiperparÃ¡metros
- Grid Search
- SelecciÃ³n de mejores features

---

### ğŸ”§ Resultados de OptimizaciÃ³n (MAE)

| Estrategia                  | Random Forest | XGBoost    |
|----------------------------|----------------|------------|
| Baseline                   | 1440.67        | 1496.03    |
| Mejores HiperparÃ¡metros    | 1410.67        | 1386.53    |
| Grid Search                | 1496.78        | **1358.74**|
| SelecciÃ³n de Features      | 1553.23        | 1562.91    |

---

## ğŸ Resultados Finales

- âœ… **XGBoost + GridSearch** fue el modelo mÃ¡s preciso con un MAE de **1358.74**.
- ğŸŸ¡ **Random Forest** tuvo buen rendimiento pero fue superado tanto en precisiÃ³n como en eficiencia.

---

## ğŸ§¾ Conclusiones

- ğŸ”¥ **XGBoost se posiciona como el mejor modelo**, combinando velocidad y precisiÃ³n gracias a su capacidad de boosting secuencial y ajuste fino de hiperparÃ¡metros.
- âš–ï¸ **Random Forest**, aunque mÃ¡s interpretable y robusto, presentÃ³ un MAE ligeramente mayor y mayor tiempo de entrenamiento.
- ğŸš« La **reducciÃ³n de features no mejorÃ³ el rendimiento**, evidenciando la importancia de mantener la riqueza del dataset completo.
- ğŸ§ª **Grid Search fue clave** para mejorar el rendimiento de XGBoost, mostrando la importancia de la bÃºsqueda sistemÃ¡tica de combinaciones.

---

**Autor:** Mayco Castellanos  
**Curso:** *Machine Learning Models*  
